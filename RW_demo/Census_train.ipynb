{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./census_training_app’: File exists\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Make app directory, which will hold the training code, __init__.py and setup.py (as required by python)\n",
    "!mkdir ./census_training_app\n",
    "# Make a blank __init__.py (required, but blank because we do not need to import any classes or do other initialization actions in this case)\n",
    "!touch ./census_training_app/__init__.py\n",
    "\n",
    "\n",
    "#!gsutil cp ./__init__.py gs://ml-demo-rw/CAIP_train_demo/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./census_training_app/train.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%writefile ./census_training_app/train.py\n",
    "## Train model and upload model to Cloud Storage\n",
    "## Also, write this code to a file in our app directory\n",
    "import argparse\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--bucket-name\", help=\"The bucket name\", required=True)\n",
    "\n",
    "arguments, unknown = parser.parse_known_args()\n",
    "bucket_name = arguments.bucket_name\n",
    "\n",
    "# Define the format of your input data, including unused columns.\n",
    "# These are the columns from the census data files.\n",
    "COLUMNS = (\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income-level'\n",
    ")\n",
    "\n",
    "# Categorical columns are columns that need to be turned into a numerical value\n",
    "# to be used by scikit-learn\n",
    "CATEGORICAL_COLUMNS = (\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country'\n",
    ")\n",
    "\n",
    "# Create a Cloud Storage client to download the census data\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Download the data\n",
    "public_bucket = storage_client.bucket('cloud-samples-data')\n",
    "blob = public_bucket.blob('ml-engine/sklearn/census_data/adult.data')\n",
    "blob.download_to_filename('adult.data')\n",
    "\n",
    "# Load the training census dataset\n",
    "with open(\"./adult.data\", \"r\") as train_data:\n",
    "    raw_training_data = pd.read_csv(train_data, header=None, names=COLUMNS)\n",
    "    # Removing the whitespaces in categorical features\n",
    "    for col in CATEGORICAL_COLUMNS:\n",
    "        raw_training_data[col] = raw_training_data[col].apply(lambda x: str(x).strip())\n",
    "\n",
    "# Remove the column we are trying to predict ('income-level') from our features\n",
    "# list and convert the DataFrame to a lists of lists\n",
    "train_features = raw_training_data.drop(\"income-level\", axis=1).values.tolist()\n",
    "# Create our training labels list, convert the DataFrame to a lists of lists\n",
    "train_labels = (raw_training_data[\"income-level\"] == \" >50K\").values.tolist()\n",
    "\n",
    "# Since the census data set has categorical features, we need to convert\n",
    "# them to numerical values. We'll use a list of pipelines to convert each\n",
    "# categorical column and then use FeatureUnion to combine them before calling\n",
    "# the RandomForestClassifier.\n",
    "categorical_pipelines = []\n",
    "\n",
    "# Each categorical column needs to be extracted individually and converted to a\n",
    "# numerical value. To do this, each categorical column will use a pipeline that\n",
    "# extracts one feature column via SelectKBest(k=1) and a LabelBinarizer() to\n",
    "# convert the categorical value to a numerical one. A scores array (created\n",
    "# below) will select and extract the feature column. The scores array is\n",
    "# created by iterating over the columns and checking if it is a\n",
    "# categorical column.\n",
    "for i, col in enumerate(COLUMNS[:-1]):\n",
    "    if col in CATEGORICAL_COLUMNS:\n",
    "        # Create a scores array to get the individual categorical column.\n",
    "        # Example:\n",
    "        #  data = [\n",
    "        #      39, 'State-gov', 77516, 'Bachelors', 13, 'Never-married',\n",
    "        #      'Adm-clerical', 'Not-in-family', 'White', 'Male', 2174, 0,\n",
    "        #      40, 'United-States'\n",
    "        #  ]\n",
    "        #  scores = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        #\n",
    "        # Returns: [['State-gov']]\n",
    "        # Build the scores array\n",
    "        scores = [0] * len(COLUMNS[:-1])\n",
    "        # This column is the categorical column we want to extract.\n",
    "        scores[i] = 1\n",
    "        skb = SelectKBest(k=1)\n",
    "        skb.scores_ = scores\n",
    "        # Convert the categorical column to a numerical value\n",
    "        lbn = LabelBinarizer()\n",
    "        r = skb.transform(train_features)\n",
    "        lbn.fit(r)\n",
    "        # Create the pipeline to extract the categorical feature\n",
    "        categorical_pipelines.append(\n",
    "            (\n",
    "                'categorical-{}'.format(i), \n",
    "                 Pipeline([\n",
    "                    ('SKB-{}'.format(i), skb),\n",
    "                    ('LBN-{}'.format(i), lbn)])\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Create pipeline to extract the numerical features\n",
    "skb = SelectKBest(k=6)\n",
    "# From COLUMNS use the features that are numerical\n",
    "skb.scores_ = [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
    "categorical_pipelines.append((\"numerical\", skb))\n",
    "\n",
    "# Combine all the features using FeatureUnion\n",
    "preprocess = FeatureUnion(categorical_pipelines)\n",
    "\n",
    "# Create the classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Transform the features and fit them to the classifier\n",
    "classifier.fit(preprocess.transform(train_features), train_labels)\n",
    "\n",
    "# Create the overall model as a single pipeline\n",
    "pipeline = Pipeline([(\"union\", preprocess), (\"classifier\", classifier)])\n",
    "\n",
    "# Create the model file\n",
    "# It is required to name the model file \"model.pkl\" if you are using pickle\n",
    "model_filename = \"model.pkl\"\n",
    "with open(model_filename, \"wb\") as model_file:\n",
    "    pickle.dump(pipeline, model_file)\n",
    "\n",
    "# Upload the model to Cloud Storage\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(model_filename)\n",
    "blob.upload_from_filename(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job [census_training_1594237895] submitted successfully.\n",
      "INFO\t2020-07-08 19:51:36 +0000\tservice\t\tValidating job requirements...\n",
      "INFO\t2020-07-08 19:51:37 +0000\tservice\t\tJob creation request has been successfully validated.\n",
      "INFO\t2020-07-08 19:51:37 +0000\tservice\t\tWaiting for job to be provisioned.\n",
      "INFO\t2020-07-08 19:51:37 +0000\tservice\t\tJob census_training_1594237895 is queued.\n",
      "INFO\t2020-07-08 19:51:39 +0000\tservice\t\tWaiting for training program to start.\n",
      "INFO\t2020-07-08 19:52:41 +0000\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"127.0.0.1:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={  \"package_uris\": [\"gs://ml-demo-rw/CAIP_train_demo/jobdir/packages/d57090bfc3fff4e012f2e5245592d564018058600e748559aaf20d3d58b0ebf5/census_training_app-0.0.0.tar.gz\"],  \"python_module\": \"train.py\",  \"args\": [\"--bucket-name\", \"ml-demo-rw/CAIP_train_demo/saved_model\"],  \"region\": \"us-central1\",  \"runtime_version\": \"1.12\",  \"job_dir\": \"gs://ml-demo-rw/CAIP_train_demo/jobdir\",  \"run_on_raw_vm\": true,  \"python_version\": \"3.5\"}\n",
      "INFO\t2020-07-08 19:53:13 +0000\tmaster-replica-0\t\tRunning module train.py.\n",
      "INFO\t2020-07-08 19:53:13 +0000\tmaster-replica-0\t\tDownloading the package: gs://ml-demo-rw/CAIP_train_demo/jobdir/packages/d57090bfc3fff4e012f2e5245592d564018058600e748559aaf20d3d58b0ebf5/census_training_app-0.0.0.tar.gz\n",
      "INFO\t2020-07-08 19:53:13 +0000\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://ml-demo-rw/CAIP_train_demo/jobdir/packages/d57090bfc3fff4e012f2e5245592d564018058600e748559aaf20d3d58b0ebf5/census_training_app-0.0.0.tar.gz census_training_app-0.0.0.tar.gz\n",
      "INFO\t2020-07-08 19:53:14 +0000\tmaster-replica-0\t\tInstalling the package: gs://ml-demo-rw/CAIP_train_demo/jobdir/packages/d57090bfc3fff4e012f2e5245592d564018058600e748559aaf20d3d58b0ebf5/census_training_app-0.0.0.tar.gz\n",
      "INFO\t2020-07-08 19:53:14 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user --upgrade --force-reinstall --no-deps census_training_app-0.0.0.tar.gz\n",
      "INFO\t2020-07-08 19:53:15 +0000\tmaster-replica-0\t\tProcessing ./census_training_app-0.0.0.tar.gz\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: census-training-app\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\t  Building wheel for census-training-app (setup.py): started\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\t  Building wheel for census-training-app (setup.py): finished with status 'done'\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\t  Created wheel for census-training-app: filename=census_training_app-0.0.0-py3-none-any.whl size=3357 sha256=01d4170b3f546f22873c8c8ebe0c084ce87431099c6440bdae781ae3866350be\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/e2/b3/e7/af1a3389506fb18db0347fc5b1b82661bb924fe87b8c2773a7\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\tSuccessfully built census-training-app\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\tInstalling collected packages: census-training-app\n",
      "INFO\t2020-07-08 19:53:16 +0000\tmaster-replica-0\t\tSuccessfully installed census-training-app-0.0.0\n",
      "ERROR\t2020-07-08 19:53:17 +0000\tmaster-replica-0\t\tWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "ERROR\t2020-07-08 19:53:17 +0000\tmaster-replica-0\t\tYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\n",
      "INFO\t2020-07-08 19:53:17 +0000\tmaster-replica-0\t\tRunning command: pip3 install --user census_training_app-0.0.0.tar.gz\n",
      "INFO\t2020-07-08 19:53:17 +0000\tmaster-replica-0\t\tProcessing ./census_training_app-0.0.0.tar.gz\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\tBuilding wheels for collected packages: census-training-app\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\t  Building wheel for census-training-app (setup.py): started\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/Grammar.txt\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\tGenerating grammar tables from /usr/lib/python3.5/lib2to3/PatternGrammar.txt\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\t  Building wheel for census-training-app (setup.py): finished with status 'done'\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\t  Created wheel for census-training-app: filename=census_training_app-0.0.0-py3-none-any.whl size=3357 sha256=6132efef36b38b7d287e3331e6338d0f883ccdf32fd8bf232f39ac9e813e3cd4\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/e2/b3/e7/af1a3389506fb18db0347fc5b1b82661bb924fe87b8c2773a7\n",
      "INFO\t2020-07-08 19:53:18 +0000\tmaster-replica-0\t\tSuccessfully built census-training-app\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\tInstalling collected packages: census-training-app\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\t  Attempting uninstall: census-training-app\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\t    Found existing installation: census-training-app 0.0.0\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\t    Uninstalling census-training-app-0.0.0:\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\t      Successfully uninstalled census-training-app-0.0.0\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\tSuccessfully installed census-training-app-0.0.0\n",
      "ERROR\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\tWARNING: You are using pip version 20.1; however, version 20.1.1 is available.\n",
      "ERROR\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\tYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\tRunning command: python3 -m train.py --bucket-name ml-demo-rw/CAIP_train_demo/saved_model --job-dir gs://ml-demo-rw/CAIP_train_demo/jobdir\n",
      "ERROR\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\t/usr/local/bin/python3: Error while finding spec for 'train.py' (ImportError: No module named 'train')\n",
      "ERROR\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\tCommand '['python3', '-m', 'train.py', '--bucket-name', 'ml-demo-rw/CAIP_train_demo/saved_model', '--job-dir', 'gs://ml-demo-rw/CAIP_train_demo/jobdir']' returned non-zero exit status 1\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2020-07-08 19:53:19 +0000\tmaster-replica-0\t\tClean up finished.\n",
      "ERROR\t2020-07-08 19:53:21 +0000\tservice\t\tThe replica master 0 exited with a non-zero status of 1. To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=811582753906&resource=ml_job%2Fjob_id%2Fcensus_training_1594237895&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%22census_training_1594237895%22\n",
      "INFO\t2020-07-08 19:55:24 +0000\tservice\t\tJob failed.\n",
      "endTime: '2020-07-08T19:55:24'\n",
      "jobId: census_training_1594237895\n",
      "startTime: '2020-07-08T19:52:51'\n",
      "state: FAILED\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a timestamped job name\n",
    "JOB_NAME = \"census_training_{}\".format(int(time.time()))\n",
    "\n",
    "# Submit the training job\n",
    "# AI Platform will automatically create a setup.py file that will install all of the packages you name in your import statements from pipy\n",
    "!gcloud ai-platform jobs submit training $JOB_NAME \\\n",
    "  --job-dir gs://ml-demo-rw/CAIP_train_demo/jobdir \\\n",
    "  --package-path ./census_training_app \\\n",
    "  --module-name train.py \\\n",
    "  --region us-central1 \\\n",
    "  --runtime-version=1.12 \\\n",
    "  --python-version=3.5 \\\n",
    "  --scale-tier BASIC \\\n",
    "  --stream-logs \\\n",
    "  -- \\\n",
    "  --bucket-name ml-demo-rw/CAIP_train_demo/saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "You've got your model all packaged up, dependencies included...but maybe you've been coding on ai notebooks. \n",
    "Maybe you haven't gone through that process, of packing your app, which can be really annoying. Use scheduled notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"CensusPredictor\"\n",
    "VERSION_NAME = \"census_predictor_{}\".format(int(time.time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "Created ml engine model [projects/remy-sandbox/models/CensusPredictor].\n",
      "\n",
      "\n",
      "To take a quick anonymous survey, run:\n",
      "  $ gcloud survey\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Create the model\n",
    "!gcloud ai-platform models create $MODEL_NAME --regions us-central1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m The `gcloud ml-engine` commands have been renamed and will soon be removed. Please use `gcloud ai-platform` instead.\n",
      "\u001b[1;31mERROR:\u001b[0m (gcloud.ml-engine.versions.create) FAILED_PRECONDITION: Field: version.deployment_uri Error: Deployment directory gs://ml-demo-rw/CAIP_train_demo/ is expected to contain exactly one of: [model.pkl, model.joblib].\n",
      "- '@type': type.googleapis.com/google.rpc.BadRequest\n",
      "  fieldViolations:\n",
      "  - description: 'Deployment directory gs://ml-demo-rw/CAIP_train_demo/ is expected\n",
      "      to contain exactly one of: [model.pkl, model.joblib].'\n",
      "    field: version.deployment_uri\n"
     ]
    }
   ],
   "source": [
    "## Deploy the model\n",
    "!gcloud ai-platform versions create $VERSION_NAME \\\n",
    "  --model=$MODEL_NAME \\\n",
    "  --framework=scikit-learn \\\n",
    "  --origin=gs://ml-demo-rw/CAIP_train_demo/ \\\n",
    "  --python-version=3.5 \\\n",
    "  --runtime-version=1.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!PATCH https://ml.googleapis.com/v1/{name=projects/*/models/*/versions/*} \\\n",
    "   { \"name\" : \"CensusPredictor\", \"requestLoggingConfig\": { \n",
    "  \"samplingPercentage\": 100,\n",
    "  \"bigqueryTableName\": \"remy-sandbox.Mics.response_request_logs\"\n",
    "    }\n",
    "   } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests.patch(https://ml.googleapis.com/v1/{name=projects/*/models/*/versions/*}, params={ \"name\" : \"CensusPredictor\", \"requestLoggingConfig\": { \n",
    "  \"samplingPercentage\": 100,\n",
    "  \"bigqueryTableName\": \"remy-sandbox.Mics.response_request_logs\"\n",
    "    }\n",
    "   }, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now set up BQ request-response logging"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
