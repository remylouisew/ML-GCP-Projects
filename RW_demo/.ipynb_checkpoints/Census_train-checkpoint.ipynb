{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train model and upload model to Cloud Storage\n",
    "\n",
    "import argparse\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from google.cloud import storage\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--bucket-name\", help=\"The bucket name\", required=True)\n",
    "\n",
    "arguments, unknown = parser.parse_known_args()\n",
    "bucket_name = arguments.bucket_name\n",
    "\n",
    "# Define the format of your input data, including unused columns.\n",
    "# These are the columns from the census data files.\n",
    "COLUMNS = (\n",
    "    'age',\n",
    "    'workclass',\n",
    "    'fnlwgt',\n",
    "    'education',\n",
    "    'education-num',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'capital-gain',\n",
    "    'capital-loss',\n",
    "    'hours-per-week',\n",
    "    'native-country',\n",
    "    'income-level'\n",
    ")\n",
    "\n",
    "# Categorical columns are columns that need to be turned into a numerical value\n",
    "# to be used by scikit-learn\n",
    "CATEGORICAL_COLUMNS = (\n",
    "    'workclass',\n",
    "    'education',\n",
    "    'marital-status',\n",
    "    'occupation',\n",
    "    'relationship',\n",
    "    'race',\n",
    "    'sex',\n",
    "    'native-country'\n",
    ")\n",
    "\n",
    "# Create a Cloud Storage client to download the census data\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Download the data\n",
    "public_bucket = storage_client.bucket('cloud-samples-data')\n",
    "blob = public_bucket.blob('ml-engine/sklearn/census_data/adult.data')\n",
    "blob.download_to_filename('adult.data')\n",
    "\n",
    "# Load the training census dataset\n",
    "with open(\"./adult.data\", \"r\") as train_data:\n",
    "    raw_training_data = pd.read_csv(train_data, header=None, names=COLUMNS)\n",
    "    # Removing the whitespaces in categorical features\n",
    "    for col in CATEGORICAL_COLUMNS:\n",
    "        raw_training_data[col] = raw_training_data[col].apply(lambda x: str(x).strip())\n",
    "\n",
    "# Remove the column we are trying to predict ('income-level') from our features\n",
    "# list and convert the DataFrame to a lists of lists\n",
    "train_features = raw_training_data.drop(\"income-level\", axis=1).values.tolist()\n",
    "# Create our training labels list, convert the DataFrame to a lists of lists\n",
    "train_labels = (raw_training_data[\"income-level\"] == \" >50K\").values.tolist()\n",
    "\n",
    "# Since the census data set has categorical features, we need to convert\n",
    "# them to numerical values. We'll use a list of pipelines to convert each\n",
    "# categorical column and then use FeatureUnion to combine them before calling\n",
    "# the RandomForestClassifier.\n",
    "categorical_pipelines = []\n",
    "\n",
    "# Each categorical column needs to be extracted individually and converted to a\n",
    "# numerical value. To do this, each categorical column will use a pipeline that\n",
    "# extracts one feature column via SelectKBest(k=1) and a LabelBinarizer() to\n",
    "# convert the categorical value to a numerical one. A scores array (created\n",
    "# below) will select and extract the feature column. The scores array is\n",
    "# created by iterating over the columns and checking if it is a\n",
    "# categorical column.\n",
    "for i, col in enumerate(COLUMNS[:-1]):\n",
    "    if col in CATEGORICAL_COLUMNS:\n",
    "        # Create a scores array to get the individual categorical column.\n",
    "        # Example:\n",
    "        #  data = [\n",
    "        #      39, 'State-gov', 77516, 'Bachelors', 13, 'Never-married',\n",
    "        #      'Adm-clerical', 'Not-in-family', 'White', 'Male', 2174, 0,\n",
    "        #      40, 'United-States'\n",
    "        #  ]\n",
    "        #  scores = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "        #\n",
    "        # Returns: [['State-gov']]\n",
    "        # Build the scores array\n",
    "        scores = [0] * len(COLUMNS[:-1])\n",
    "        # This column is the categorical column we want to extract.\n",
    "        scores[i] = 1\n",
    "        skb = SelectKBest(k=1)\n",
    "        skb.scores_ = scores\n",
    "        # Convert the categorical column to a numerical value\n",
    "        lbn = LabelBinarizer()\n",
    "        r = skb.transform(train_features)\n",
    "        lbn.fit(r)\n",
    "        # Create the pipeline to extract the categorical feature\n",
    "        categorical_pipelines.append(\n",
    "            (\n",
    "                'categorical-{}'.format(i), \n",
    "                 Pipeline([\n",
    "                    ('SKB-{}'.format(i), skb),\n",
    "                    ('LBN-{}'.format(i), lbn)])\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Create pipeline to extract the numerical features\n",
    "skb = SelectKBest(k=6)\n",
    "# From COLUMNS use the features that are numerical\n",
    "skb.scores_ = [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0]\n",
    "categorical_pipelines.append((\"numerical\", skb))\n",
    "\n",
    "# Combine all the features using FeatureUnion\n",
    "preprocess = FeatureUnion(categorical_pipelines)\n",
    "\n",
    "# Create the classifier\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "# Transform the features and fit them to the classifier\n",
    "classifier.fit(preprocess.transform(train_features), train_labels)\n",
    "\n",
    "# Create the overall model as a single pipeline\n",
    "pipeline = Pipeline([(\"union\", preprocess), (\"classifier\", classifier)])\n",
    "\n",
    "# Create the model file\n",
    "# It is required to name the model file \"model.pkl\" if you are using pickle\n",
    "model_filename = \"model.pkl\"\n",
    "with open(model_filename, \"wb\") as model_file:\n",
    "    pickle.dump(pipeline, model_file)\n",
    "\n",
    "# Upload the model to Cloud Storage\n",
    "bucket = storage_client.bucket(bucket_name)\n",
    "blob = bucket.blob(model_filename)\n",
    "blob.upload_from_filename(model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
