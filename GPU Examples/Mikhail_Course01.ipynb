{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Introduction to TensorFlow for Artificial Intelligence, Machine Learning, and Deep Learning\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Week 1 (Template for Keras)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import os\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(tf.__version__)\\n\",\n",
    "    \"print(\\\"Num GPUs Available: \\\", len(tf.config.experimental.list_physical_devices('GPU')))\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.compile(optimizer='sgd', loss='mean_squared_error')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\\n\",\n",
    "    \"ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.fit(xs, ys, epochs=500)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(model.predict([10.0]))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Week 2 (Simple DNN) & 3 (CNN)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"#print(os.environ)\\n\",\n",
    "    \"#os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"-1\\\"\\n\",\n",
    "    \"#print(os.environ[\\\"CUDA_VISIBLE_DEVICES\\\"])\\n\",\n",
    "    \"import time\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"print(tf.__version__)\\n\",\n",
    "    \"print(\\\"Num GPUs Available: \\\", len(tf.config.experimental.list_physical_devices('GPU')))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"mnist = tf.keras.datasets.fashion_mnist\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"np.set_printoptions(linewidth=200)\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"plt.imshow(training_images[0])\\n\",\n",
    "    \"#print(training_labels[0])\\n\",\n",
    "    \"#print(training_images[0])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"training_images  = training_images / 255.0\\n\",\n",
    "    \"test_images = test_images / 255.0\\n\",\n",
    "    \"\\n\",\n",
    "    \"training_images_cnn=training_images.reshape(60000, 28, 28, 1)\\n\",\n",
    "    \"test_images_cnn = test_images.reshape(10000, 28, 28, 1)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(training_images.shape)\\n\",\n",
    "    \"print(test_images.shape)\\n\",\n",
    "    \"print(training_images_cnn.shape)\\n\",\n",
    "    \"print(test_images_cnn.shape)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"modeldnn = tf.keras.models.Sequential([\\n\",\n",
    "    \"                                    #tf.keras.layers.Flatten(input_shape=(28,28)), \\n\",\n",
    "    \"                                    tf.keras.layers.Flatten(), \\n\",\n",
    "    \"                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), \\n\",\n",
    "    \"                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), \\n\",\n",
    "    \"                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\\n\",\n",
    "    \"\\n\",\n",
    "    \"#Why doesn't it error out when last layer doesn't match number of classes?\\n\",\n",
    "    \"\\n\",\n",
    "    \"modelcnn = tf.keras.models.Sequential([\\n\",\n",
    "    \"                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\\n\",\n",
    "    \"                                    tf.keras.layers.MaxPooling2D(2, 2),\\n\",\n",
    "    \"                                    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\\n\",\n",
    "    \"                                    tf.keras.layers.MaxPooling2D(2,2), \\n\",\n",
    "    \"                                    tf.keras.layers.Flatten(), \\n\",\n",
    "    \"                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), \\n\",\n",
    "    \"                                    tf.keras.layers.Dense(512, activation=tf.nn.relu), \\n\",\n",
    "    \"                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class myCallback(tf.keras.callbacks.Callback):\\n\",\n",
    "    \"  def on_epoch_end(self, epoch, logs={}):\\n\",\n",
    "    \"    if(logs.get('accuracy')>.99):\\n\",\n",
    "    \"      print(\\\"\\\\nReached 99% accuracy so cancelling training!\\\")\\n\",\n",
    "    \"      self.model.stop_training = True\\n\",\n",
    "    \"callbacks = myCallback()\\n\",\n",
    "    \"        \\n\",\n",
    "    \"modeldnn.compile(optimizer = tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\\n\",\n",
    "    \"modelcnn.compile(optimizer = tf.optimizers.Adam(), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\\n\",\n",
    "    \"modeldnn.summary()\\n\",\n",
    "    \"modelcnn.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"\\n\",\n",
    "    \"start = time.time()\\n\",\n",
    "    \"#model.fit(training_images, training_labels, epochs=5, batch_size=128)\\n\",\n",
    "    \"modeldnn.fit(training_images, training_labels, epochs=20, callbacks=[callbacks])\\n\",\n",
    "    \"end = time.time()\\n\",\n",
    "    \"print(end - start)\\n\",\n",
    "    \"test_loss = modeldnn.evaluate(test_images, test_labels)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"test_loss = modeldnn.evaluate(test_images, test_labels)\\n\",\n",
    "    \"print(test_loss)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"start = time.time()\\n\",\n",
    "    \"#model.fit(training_images, training_labels, epochs=5, batch_size=128)\\n\",\n",
    "    \"modelcnn.fit(training_images_cnn, training_labels, epochs=20, callbacks=[callbacks])\\n\",\n",
    "    \"end = time.time()\\n\",\n",
    "    \"print(end - start)\\n\",\n",
    "    \"test_loss = modelcnn.evaluate(test_images_cnn, test_labels)\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"classifications = model.predict(test_images)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(classifications[1])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(test_labels[:100])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"#not working\\n\",\n",
    "    \"\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"f, axarr = plt.subplots(3,4)\\n\",\n",
    "    \"FIRST_IMAGE=0\\n\",\n",
    "    \"SECOND_IMAGE=7\\n\",\n",
    "    \"THIRD_IMAGE=26\\n\",\n",
    "    \"CONVOLUTION_NUMBER = 1\\n\",\n",
    "    \"from tensorflow.keras import models\\n\",\n",
    "    \"layer_outputs = [layer.output for layer in modelcnn.layers]\\n\",\n",
    "    \"activation_model = tf.keras.models.Model(inputs = modelcnn.input, outputs = layer_outputs)\\n\",\n",
    "    \"for x in range(0,4):\\n\",\n",
    "    \"  f1 = activation_model.predict(test_images_cnn[FIRST_IMAGE].reshape(1, 28, 28, 1))[x]\\n\",\n",
    "    \"  axarr[0,x].imshow(f1[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\\n\",\n",
    "    \"  axarr[0,x].grid(False)\\n\",\n",
    "    \"  f2 = activation_model.predict(test_images_cnn[SECOND_IMAGE].reshape(1, 28, 28, 1))[x]\\n\",\n",
    "    \"  axarr[1,x].imshow(f2[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\\n\",\n",
    "    \"  axarr[1,x].grid(False)\\n\",\n",
    "    \"  f3 = activation_model.predict(test_images_cnn[THIRD_IMAGE].reshape(1, 28, 28, 1))[x]\\n\",\n",
    "    \"  axarr[2,x].imshow(f3[0, : , :, CONVOLUTION_NUMBER], cmap='inferno')\\n\",\n",
    "    \"  axarr[2,x].grid(False)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Week 4 (Image Generator + Validation Loop)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"!pwd\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"!wget --no-check-certificate \\\\\\n\",\n",
    "    \"    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\\\\n\",\n",
    "    \"    -O /tmp/horse-or-human.zip\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"!wget --no-check-certificate \\\\\\n\",\n",
    "    \"    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip \\\\\\n\",\n",
    "    \"    -O /tmp/validation-horse-or-human.zip\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import os\\n\",\n",
    "    \"import zipfile\\n\",\n",
    "    \"\\n\",\n",
    "    \"local_zip = '/tmp/horse-or-human.zip'\\n\",\n",
    "    \"zip_ref = zipfile.ZipFile(local_zip, 'r')\\n\",\n",
    "    \"zip_ref.extractall('/tmp/horse-or-human')\\n\",\n",
    "    \"local_zip = '/tmp/validation-horse-or-human.zip'\\n\",\n",
    "    \"zip_ref = zipfile.ZipFile(local_zip, 'r')\\n\",\n",
    "    \"zip_ref.extractall('/tmp/validation-horse-or-human')\\n\",\n",
    "    \"zip_ref.close()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Directory with our training horse pictures\\n\",\n",
    "    \"train_horse_dir = os.path.join('/tmp/horse-or-human/horses')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Directory with our training human pictures\\n\",\n",
    "    \"train_human_dir = os.path.join('/tmp/horse-or-human/humans')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Directory with our training horse pictures\\n\",\n",
    "    \"validation_horse_dir = os.path.join('/tmp/validation-horse-or-human/horses')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Directory with our training human pictures\\n\",\n",
    "    \"validation_human_dir = os.path.join('/tmp/validation-horse-or-human/humans')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"train_horse_names = os.listdir(train_horse_dir)\\n\",\n",
    "    \"print(train_horse_names[:10])\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_human_names = os.listdir(train_human_dir)\\n\",\n",
    "    \"print(train_human_names[:10])\\n\",\n",
    "    \"\\n\",\n",
    "    \"validation_horse_hames = os.listdir(validation_horse_dir)\\n\",\n",
    "    \"print(validation_horse_hames[:10])\\n\",\n",
    "    \"\\n\",\n",
    "    \"validation_human_names = os.listdir(validation_human_dir)\\n\",\n",
    "    \"print(validation_human_names[:10])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print('total training horse images:', len(os.listdir(train_horse_dir)))\\n\",\n",
    "    \"print('total training human images:', len(os.listdir(train_human_dir)))\\n\",\n",
    "    \"print('total validation horse images:', len(os.listdir(validation_horse_dir)))\\n\",\n",
    "    \"print('total validation human images:', len(os.listdir(validation_human_dir)))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"%matplotlib inline\\n\",\n",
    "    \"\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import matplotlib.image as mpimg\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Parameters for our graph; we'll output images in a 4x4 configuration\\n\",\n",
    "    \"nrows = 4\\n\",\n",
    "    \"ncols = 4\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Index for iterating over images\\n\",\n",
    "    \"pic_index = 0\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Set up matplotlib fig, and size it to fit 4x4 pics\\n\",\n",
    "    \"fig = plt.gcf()\\n\",\n",
    "    \"fig.set_size_inches(ncols * 4, nrows * 4)\\n\",\n",
    "    \"\\n\",\n",
    "    \"pic_index += 8\\n\",\n",
    "    \"next_horse_pix = [os.path.join(train_horse_dir, fname) \\n\",\n",
    "    \"                for fname in train_horse_names[pic_index-8:pic_index]]\\n\",\n",
    "    \"next_human_pix = [os.path.join(train_human_dir, fname) \\n\",\n",
    "    \"                for fname in train_human_names[pic_index-8:pic_index]]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, img_path in enumerate(next_horse_pix+next_human_pix):\\n\",\n",
    "    \"  # Set up subplot; subplot indices start at 1\\n\",\n",
    "    \"  sp = plt.subplot(nrows, ncols, i + 1)\\n\",\n",
    "    \"  sp.axis('Off') # Don't show axes (or gridlines)\\n\",\n",
    "    \"\\n\",\n",
    "    \"  img = mpimg.imread(img_path)\\n\",\n",
    "    \"  plt.imshow(img)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import tensorflow as tf\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model = tf.keras.models.Sequential([\\n\",\n",
    "    \"    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\\n\",\n",
    "    \"    # This is the first convolution\\n\",\n",
    "    \"    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\\n\",\n",
    "    \"    tf.keras.layers.MaxPooling2D(2, 2),\\n\",\n",
    "    \"    # The second convolution\\n\",\n",
    "    \"    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\\n\",\n",
    "    \"    tf.keras.layers.MaxPooling2D(2,2),\\n\",\n",
    "    \"    # The third convolution\\n\",\n",
    "    \"    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\\n\",\n",
    "    \"    tf.keras.layers.MaxPooling2D(2,2),\\n\",\n",
    "    \"    # The fourth convolution\\n\",\n",
    "    \"    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\\n\",\n",
    "    \"    tf.keras.layers.MaxPooling2D(2,2),\\n\",\n",
    "    \"    # The fifth convolution\\n\",\n",
    "    \"    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\\n\",\n",
    "    \"    tf.keras.layers.MaxPooling2D(2,2),\\n\",\n",
    "    \"    # Flatten the results to feed into a DNN\\n\",\n",
    "    \"    tf.keras.layers.Flatten(),\\n\",\n",
    "    \"    # 512 neuron hidden layer\\n\",\n",
    "    \"    tf.keras.layers.Dense(512, activation='relu'),\\n\",\n",
    "    \"    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\\n\",\n",
    "    \"    tf.keras.layers.Dense(1, activation='sigmoid')\\n\",\n",
    "    \"])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"model.summary()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from tensorflow.keras.optimizers import RMSprop\\n\",\n",
    "    \"\\n\",\n",
    "    \"model.compile(loss='binary_crossentropy',\\n\",\n",
    "    \"              optimizer=RMSprop(lr=0.001),\\n\",\n",
    "    \"              metrics=['accuracy'])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from tensorflow.keras.preprocessing.image import ImageDataGenerator\\n\",\n",
    "    \"\\n\",\n",
    "    \"# All images will be rescaled by 1./255\\n\",\n",
    "    \"train_datagen = ImageDataGenerator(rescale=1/255)\\n\",\n",
    "    \"validation_datagen = ImageDataGenerator(rescale=1/255)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Flow training images in batches of 128 using train_datagen generator\\n\",\n",
    "    \"train_generator = train_datagen.flow_from_directory(\\n\",\n",
    "    \"        '/tmp/horse-or-human/',  # This is the source directory for training images\\n\",\n",
    "    \"        target_size=(300, 300),  # All images will be resized to 150x150\\n\",\n",
    "    \"        batch_size=128,\\n\",\n",
    "    \"        # Since we use binary_crossentropy loss, we need binary labels\\n\",\n",
    "    \"        class_mode='binary')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Flow training images in batches of 128 using train_datagen generator\\n\",\n",
    "    \"validation_generator = validation_datagen.flow_from_directory(\\n\",\n",
    "    \"        '/tmp/validation-horse-or-human/',  # This is the source directory for training images\\n\",\n",
    "    \"        target_size=(300, 300),  # All images will be resized to 150x150\\n\",\n",
    "    \"        batch_size=32,\\n\",\n",
    "    \"        # Since we use binary_crossentropy loss, we need binary labels\\n\",\n",
    "    \"        class_mode='binary')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 138,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"ename\": \"RuntimeError\",\n",
    "     \"evalue\": \"You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.\",\n",
    "     \"output_type\": \"error\",\n",
    "     \"traceback\": [\n",
    "      \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
    "      \"\\u001b[0;31mRuntimeError\\u001b[0m                              Traceback (most recent call last)\",\n",
    "      \"\\u001b[0;32m<ipython-input-138-8fe91a69fd3c>\\u001b[0m in \\u001b[0;36m<module>\\u001b[0;34m\\u001b[0m\\n\\u001b[1;32m      5\\u001b[0m       \\u001b[0mverbose\\u001b[0m\\u001b[0;34m=\\u001b[0m\\u001b[0;36m1\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m      6\\u001b[0m       \\u001b[0mvalidation_data\\u001b[0m \\u001b[0;34m=\\u001b[0m \\u001b[0mvalidation_generator\\u001b[0m\\u001b[0;34m,\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m----> 7\\u001b[0;31m       validation_steps=8)\\n\\u001b[0m\",\n",
    "      \"\\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\\u001b[0m in \\u001b[0;36mfit\\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\\u001b[0m\\n\\u001b[1;32m    794\\u001b[0m     \\u001b[0;32mif\\u001b[0m \\u001b[0mkwargs\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    795\\u001b[0m       \\u001b[0;32mraise\\u001b[0m \\u001b[0mTypeError\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m'Unrecognized keyword arguments: '\\u001b[0m \\u001b[0;34m+\\u001b[0m \\u001b[0mstr\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0mkwargs\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m--> 796\\u001b[0;31m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_assert_compile_was_called\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0m\\u001b[1;32m    797\\u001b[0m     \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0m_check_call_args\\u001b[0m\\u001b[0;34m(\\u001b[0m\\u001b[0;34m'fit'\\u001b[0m\\u001b[0;34m)\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m    798\\u001b[0m \\u001b[0;34m\\u001b[0m\\u001b[0m\\n\",\n",
    "      \"\\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\\u001b[0m in \\u001b[0;36m_assert_compile_was_called\\u001b[0;34m(self)\\u001b[0m\\n\\u001b[1;32m   2826\\u001b[0m     \\u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   2827\\u001b[0m     \\u001b[0;32mif\\u001b[0m \\u001b[0;32mnot\\u001b[0m \\u001b[0mself\\u001b[0m\\u001b[0;34m.\\u001b[0m\\u001b[0moptimizer\\u001b[0m\\u001b[0;34m:\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[0;32m-> 2828\\u001b[0;31m       raise RuntimeError('You must compile your model before '\\n\\u001b[0m\\u001b[1;32m   2829\\u001b[0m                          \\u001b[0;34m'training/testing. '\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0;34m\\u001b[0m\\u001b[0m\\n\\u001b[1;32m   2830\\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\\n\",\n",
    "      \"\\u001b[0;31mRuntimeError\\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"history = model.fit(\\n\",\n",
    "    \"      train_generator,\\n\",\n",
    "    \"      steps_per_epoch=8,  \\n\",\n",
    "    \"      epochs=15,\\n\",\n",
    "    \"      verbose=1,\\n\",\n",
    "    \"      validation_data = validation_generator,\\n\",\n",
    "    \"      validation_steps=8)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import random\\n\",\n",
    "    \"from tensorflow.keras.preprocessing.image import img_to_array, load_img\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Let's define a new Model that will take an image as input, and will output\\n\",\n",
    "    \"# intermediate representations for all layers in the previous model after\\n\",\n",
    "    \"# the first.\\n\",\n",
    "    \"successive_outputs = [layer.output for layer in model.layers[1:]]\\n\",\n",
    "    \"#visualization_model = Model(img_input, successive_outputs)\\n\",\n",
    "    \"visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\\n\",\n",
    "    \"# Let's prepare a random input image from the training set.\\n\",\n",
    "    \"horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\\n\",\n",
    "    \"human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\\n\",\n",
    "    \"img_path = random.choice(horse_img_files + human_img_files)\\n\",\n",
    "    \"\\n\",\n",
    "    \"img = load_img(img_path, target_size=(300, 300))  # this is a PIL image\\n\",\n",
    "    \"x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\\n\",\n",
    "    \"x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Rescale by 1/255\\n\",\n",
    "    \"x /= 255\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Let's run our image through our network, thus obtaining all\\n\",\n",
    "    \"# intermediate representations for this image.\\n\",\n",
    "    \"successive_feature_maps = visualization_model.predict(x)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# These are the names of the layers, so can have them as part of our plot\\n\",\n",
    "    \"layer_names = [layer.name for layer in model.layers]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Now let's display our representations\\n\",\n",
    "    \"for layer_name, feature_map in zip(layer_names, successive_feature_maps):\\n\",\n",
    "    \"  if len(feature_map.shape) == 4:\\n\",\n",
    "    \"    # Just do this for the conv / maxpool layers, not the fully-connected layers\\n\",\n",
    "    \"    n_features = feature_map.shape[-1]  # number of features in feature map\\n\",\n",
    "    \"    # The feature map has shape (1, size, size, n_features)\\n\",\n",
    "    \"    size = feature_map.shape[1]\\n\",\n",
    "    \"    # We will tile our images in this matrix\\n\",\n",
    "    \"    display_grid = np.zeros((size, size * n_features))\\n\",\n",
    "    \"    for i in range(n_features):\\n\",\n",
    "    \"      # Postprocess the feature to make it visually palatable\\n\",\n",
    "    \"      x = feature_map[0, :, :, i]\\n\",\n",
    "    \"      x -= x.mean()\\n\",\n",
    "    \"      x /= x.std()\\n\",\n",
    "    \"      x *= 64\\n\",\n",
    "    \"      x += 128\\n\",\n",
    "    \"      x = np.clip(x, 0, 255).astype('uint8')\\n\",\n",
    "    \"      # We'll tile each filter into this big horizontal grid\\n\",\n",
    "    \"      display_grid[:, i * size : (i + 1) * size] = x\\n\",\n",
    "    \"    # Display the grid\\n\",\n",
    "    \"    scale = 20. / n_features\\n\",\n",
    "    \"    plt.figure(figsize=(scale * n_features, scale))\\n\",\n",
    "    \"    plt.title(layer_name)\\n\",\n",
    "    \"    plt.grid(False)\\n\",\n",
    "    \"    plt.imshow(display_grid, aspect='auto', cmap='viridis')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": []\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
